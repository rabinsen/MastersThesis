{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import random\n",
    "from random import shuffle\n",
    "from skimage.transform import rotate\n",
    "import scipy.ndimage\n",
    "from spectral import *\n",
    "import spectral.io.envi as envi\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset():\n",
    "    image = envi.open('../../hyperImage/radiance/VNIR/09_Rad_VNIR_masked.hdr', '../../hyperImage/radiance/VNIR/09_Rad_VNIR_masked')\n",
    "    data = image.load()\n",
    "    #label_data = Image.open('../../hyperImage/reflectance/vnir/training/train_gt2.tif')\n",
    "    label_data = Image.open('../../hyperImage/radiance/VNIR/class1.tif')\n",
    "    labels = np.array(label_data)\n",
    "    return data, labels\n",
    "\n",
    "def splitTrainTestSet(X, y, testRatio=0.10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=345,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def oversampleWeakClasses(X, y):\n",
    "    uniqueLabels, labelCounts = np.unique(y, return_counts=True)\n",
    "    maxCount = np.max(labelCounts)\n",
    "    labelInverseRatios = maxCount / labelCounts  \n",
    "    # repeat for every label and concat\n",
    "    newX = X[y == uniqueLabels[0], :, :, :].repeat(round(labelInverseRatios[0]), axis=0)\n",
    "    newY = y[y == uniqueLabels[0]].repeat(round(labelInverseRatios[0]), axis=0)\n",
    "    for label, labelInverseRatio in zip(uniqueLabels[1:], labelInverseRatios[1:]):\n",
    "        cX = X[y== label,:,:,:].repeat(round(labelInverseRatio), axis=0)\n",
    "        cY = y[y == label].repeat(round(labelInverseRatio), axis=0)\n",
    "        newX = np.concatenate((newX, cX))\n",
    "        newY = np.concatenate((newY, cY))\n",
    "    np.random.seed(seed=42)\n",
    "    rand_perm = np.random.permutation(newY.shape[0])\n",
    "    newX = newX[rand_perm, :, :, :]\n",
    "    newY = newY[rand_perm]\n",
    "    return newX, newY\n",
    "\n",
    "def standartizeData(X):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    scaler = preprocessing.StandardScaler().fit(newX)  \n",
    "    newX = scaler.transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1],X.shape[2]))\n",
    "    return newX, scaler\n",
    "\n",
    "def applyPCA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca\n",
    "\n",
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createPatches(X, y, windowSize=5, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels\n",
    "\n",
    "def createPatches_val(X, windowSize=5):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchIndex = patchIndex + 1\n",
    "    return patchesData\n",
    "\n",
    "def AugmentData(X_train):\n",
    "    for i in range(int(X_train.shape[0]/2)):\n",
    "        patch = X_train[i,:,:,:]\n",
    "        num = random.randint(0,2)\n",
    "        if (num == 0):\n",
    "            \n",
    "            flipped_patch = np.flipud(patch)\n",
    "        if (num == 1):\n",
    "            \n",
    "            flipped_patch = np.fliplr(patch)\n",
    "        if (num == 2):\n",
    "            \n",
    "            no = random.randrange(-180,180,30)\n",
    "            flipped_patch = scipy.ndimage.interpolation.rotate(patch, no,axes=(1, 0),\n",
    "                                                               reshape=False, output=None, order=3, mode='constant', cval=0.0, prefilter=False)\n",
    "    \n",
    "    \n",
    "    patch2 = flipped_patch\n",
    "    X_train[i,:,:,:] = patch2\n",
    "    \n",
    "    return X_train\n",
    "\n",
    "\n",
    "def savePreprocessedData(X_Patches, y_Patches, windowSize, wasPCAapplied = False, numPCAComponents = 0, testRatio = 0.25):\n",
    "    if wasPCAapplied:\n",
    "        with open(\"training/X_Patches1\" + str(windowSize) + \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) + \".npy\", 'bw') as outfile:\n",
    "             np.save(outfile, X_Patches)\n",
    "        with open(\"training/yPatches1\" + str(windowSize) + \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) + \".npy\", 'bw') as outfile:\n",
    "             np.save(outfile, y_Patches)\n",
    "        #with open(\"validation/X_vals_Patches_\" + str(windowSize) + \"PCA\" + str(numPCAComponents) + \"testRatio\" + str(testRatio) + \".npy\", 'bw') as outfile:\n",
    "         #    np.save(outfile, X_vals_Patches)\n",
    "    else:\n",
    "        with open(\"../preprocessedData/XtrainWindowSize\" + str(windowSize) + \".npy\", 'bw') as outfile:\n",
    "            np.save(outfile, X_trainPatches)\n",
    "        with open(\"../preprocessedData/XtestWindowSize\" + str(windowSize) + \".npy\", 'bw') as outfile:\n",
    "            np.save(outfile, X_testPatches)\n",
    "        with open(\"../preprocessedData/ytrainWindowSize\" + str(windowSize) + \".npy\", 'bw') as outfile:\n",
    "            np.save(outfile, y_trainPatches)\n",
    "        #with open(\"../preprocessedData/ytestWindowSize\" + str(windowSize) + \".npy\", 'bw') as outfile:\n",
    "            np.save(outfile, y_testPatches)\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Global values (windowSize, numPCAcomponents, testRatio) from the text file global_variables.txt\n",
    "myFile = open('global_variables.txt', 'r') \n",
    "file = myFile.readlines()[:]\n",
    "\n",
    "\n",
    "for line in file:\n",
    "\n",
    "    if line[0:3] == \"win\":\n",
    "\n",
    "        ds = line.find('=')\n",
    "        windowSize = int(line[ds+1:-1],10)\n",
    "\n",
    "    elif line[0:3] == \"num\":\n",
    "\n",
    "        ds = line.find('=')\n",
    "        numPCAcomponents = int(line[ds+2:-1],10)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ds = line.find('=')\n",
    "        testRatio = float(line[ds+1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loadDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, pca = applyPCA(X, numPCAcomponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPatches, yPatches = createPatches(X, y, windowSize=windowSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPatches, yPatches = oversampleWeakClasses(XPatches, yPatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPatches = AugmentData(XPatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121874, 9, 9, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XPatches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePreprocessedData(XPatches, yPatches, windowSize = windowSize, \n",
    "                     wasPCAapplied=True, numPCAComponents = numPCAcomponents,testRatio = testRatio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 2296, 186)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image = envi.open('../../hyperImage/reflectance/vnir/08_clippped_road.hdr', '../../hyperImage/reflectance/vnir/08_clippped_road.')\n",
    "val_img = val_image.load()\n",
    "val_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 2296)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Class image\n",
    "gt_data_val = Image.open('../../hyperImage/reflectance/vnir/class_val.tif')\n",
    "gt_val = np.array(gt_data_val)\n",
    "gt_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, pca_val = applyPCA(val_img, numPCAcomponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449841, 9, 9, 10)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XPatches_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPatches_val, yPatches_val = createPatches(X_val, gt_val, windowSize=windowSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPatches_val, yPatches_val = oversampleWeakClasses(XPatches_val, yPatches_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPatches_val = AugmentData(XPatches_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32254, 9, 9, 10)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XPatches_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePreprocessedData(XPatches_val, yPatches_val, windowSize = windowSize, \n",
    "                     wasPCAapplied=True, numPCAComponents = numPCAcomponents,testRatio = testRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
